\documentclass{report}
\usepackage[utf8]{inputenc}

\title{Distributed Coded Computation}
\author{Pedro J. Soto}
\date{March 2021}

\begin{document}

\maketitle


\tableofcontents

\begin{abstract}
A ubiquitous problem in computer science research is the optimization of computation on large data sets. Such computations are usually too large to be preformed on one machine and therefore the task needs to be distributed amongst a network of machines. However a common problem within distributed computing is the mitigation of delays caused by faulty machines in the network. This can be performed by the use of coding theory to optimize the amount of redundancy needed to handle such faults.  This problem differs from classical coding theory insofar that it is concerned with the dynamic coded computation on data rather than just statically coding data without any consideration of the algorithms to be performed on said data. Of particular interest is the operation of matrix multiplication, which happens to be a fundamental operation in many big data/machine learning algorithms, which is the main focus of this paper. A wonderful coincide of the (bi-)linear nature of matrix multiplication is that it is both highly parrallelizable and that linear codes can be applied to it; making the coding theory approach a successful avenue of research for this particular optimization of distributed computing. 
\end{abstract}

\section{Introduction}

\section{Background}

\subsection{Coding Theory}

\subsection{Linear Algebra and Learning Algorithms}



\section{Related Works}

\subsection{Poly Codes}

\subsection{Machine Learning}




\section{Our Work}

\subsection{Dual Entangled}

\subsection{Spinner}

\subsection{Rook Poly}

\end{document}
